{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datacleaningfuncs import *\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import database of structured information from books and the web\n",
    "database = pd.read_pickle('databasefrom1.pickle')\n",
    "text = pd.read_pickle('databasetextcomponentfrom1.pickle')\n",
    "# data containing the document id's and the weights associated with each of them\n",
    "# documents = pd.read_pickle('documents.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing Graph of keywords\n",
    "# gKWs = nx.DiGraph()\n",
    "gKWs = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findingkeywords\n",
    "everyheadingimportance = 1\n",
    "everytextimportance = 1\n",
    "for heading in database['preprocessed_heading']:\n",
    "    for word in heading:\n",
    "        if word not in gKWs.nodes():\n",
    "            gKWs.add_node(word, importance=everyheadingimportance)\n",
    "        else:\n",
    "            gKWs.nodes[word]['importance']+=everyheadingimportance\n",
    "for paragraph in text['preprocessed_lines']:\n",
    "    for line in paragraph:\n",
    "        for word in line:\n",
    "            if word in gKWs.nodes():\n",
    "                gKWs.nodes[word]['importance']+=everytextimportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding edges between nodes\n",
    "everyheadingweight = 1\n",
    "everytextweight = 1\n",
    "for heading in database['preprocessed_heading']:\n",
    "    if len(heading)>1:\n",
    "        for i in range(len(heading)-1):\n",
    "            one = heading[i]\n",
    "            two = heading[i+1]\n",
    "            if (one, two) not in gKWs.edges():\n",
    "                gKWs.add_edge(one, two, weight=everyheadingweight)\n",
    "            else:\n",
    "                gKWs.edges[(one, two)]['weight']+=everyheadingweight\n",
    "for paragraph in text['preprocessed_lines']:\n",
    "    for line in paragraph:\n",
    "        if len(line)>1:\n",
    "            for i in range(len(line)-1):\n",
    "                one = line[i]\n",
    "                two = line[i+1]\n",
    "                if (one, two) in gKWs.edges():\n",
    "                    gKWs.edges[(one, two)]['weight']+=everytextweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing hapaxes (both nodes and edges)\n",
    "nodestoremove = []\n",
    "for node in gKWs.nodes():\n",
    "    if gKWs.nodes[node]['importance']==everyheadingimportance:\n",
    "        nodestoremove.append(node)\n",
    "gKWs.remove_nodes_from(nodestoremove)\n",
    "edgestoremove = []\n",
    "for edge in gKWs.edges():\n",
    "    if gKWs.edges[edge]['weight']==everyheadingweight:\n",
    "        edgestoremove.append(edge)\n",
    "gKWs.remove_edges_from(edgestoremove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "for node in gKWs.nodes():\n",
    "    nodeimportance = gKWs.nodes[node]['importance']\n",
    "    sumofweights = 0\n",
    "    if len(gKWs.edges(node))==0:\n",
    "        continue\n",
    "    for edge in gKWs.edges(node):\n",
    "        sumofweights+=gKWs.edges[edge]['weight']\n",
    "    if ((nodeimportance-sumofweights)/nodeimportance)>threshold:\n",
    "        keywords[node]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'importance': 1692}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gKWs.nodes['blockchain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the keyword dictionary as dictionaryofkeywords.pickle\n",
    "# with open('.pickle', 'wb') as file:\n",
    "#     pickle.dump(dictionaryofkeywords, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
